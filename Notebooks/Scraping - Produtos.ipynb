{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project - Radar Black Friday\n",
    "\n",
    "Projeto que tem como principal objetivo coletar diariamente os preços de produtos vendidos pelas principais lojas ecommerce do Brasil e acompanhar se realmente existe uma redução de preço no famoso evento Black Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose of this notebook\n",
    "Neste notebook você encontrará a etapa de coleta dos links que serão raspados.<br>\n",
    "\n",
    ">Este notebook não tem fins educativos, portanto não será explicado o conceito dos métodos ou funções, somente o objetivo das etapas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÃO DAS LIBS\n",
    "\n",
    "import sqlite3 # -- SQLite 3 - Banco de Dados\n",
    "from urllib.request import urlopen, Request #URL Lib para acessar link que será feito o Scraping\n",
    "import bs4 #BeautifulSoup para analisar página HTML\n",
    "import pandas as pd #Pandas para analisar os dados e armazenar em DataFrma\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Funções utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funções de LOG\n",
    "\n",
    "# Função para gravar o LOG de Execução da Etapa\n",
    "def log_exec(state):\n",
    "    try:\n",
    "        query = \"INSERT INTO log_exec (dt_reg, ds_step) Values (current_timestamp, '%s')\"\n",
    "        cursor.execute(query %(state))\n",
    "        cnn.commit()\n",
    "        return \"Log Execução Gravado com Sucesso\"\n",
    "    except:\n",
    "        return \"Erro gravar Log Execução\"\n",
    "    \n",
    "    \n",
    "# Função para gravar o LOG do resultado da raspagem\n",
    "def log_scraping(link, state, qt_precos, cursor):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "                INSERT INTO log_scraping \n",
    "                    (dt_insert, link_scraping, status_exec, qt_prices) \n",
    "                    VALUES (current_timestamp, '%s', '%s', %s)\n",
    "                \"\"\"\n",
    "        cursor.execute(query %(link, state, qt_precos))\n",
    "        cnn.commit()\n",
    "        return \"Log Scraping Gravado com Sucesso\"\n",
    "    except:\n",
    "        return \"Erro gravar Log Scraping\"   \n",
    "    \n",
    "    \n",
    "# Função para gravar o LOG da importação no banco de dados\n",
    "def log_insert(dt_inicio,dt_final, qt_sucesso, qt_falha):\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "                INSERT INTO log_insert_db \n",
    "                    (dt_start, dt_end, qt_success, qt_failure)\n",
    "                    Values ('%s', '%s', %s, %s)\n",
    "                \"\"\"\n",
    "        cursor.execute(query %(dt_inicio,dt_final, qt_sucesso, qt_falha ))\n",
    "        cnn.commit()\n",
    "        return \"Log Insert Gravado com Sucesso\"\n",
    "    except:\n",
    "        return \"Erro Gravar Log Insert\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para inserir os resultados no Banco de Dados\n",
    "\n",
    "def inserirRegistros(list_result):\n",
    "    \n",
    "    #Contatores\n",
    "    sucess = 0\n",
    "    failure = 0\n",
    "    \n",
    "    dt_inicio = datetime.datetime.today()\n",
    "    \n",
    "    query = \"\"\"\n",
    "            INSERT INTO scraping_results\n",
    "            (dt_insert, ds_category, ds_subcategory, ds_product, ds_ecommerce, price)\n",
    "            VALUES (current_timestamp, '%s', '%s', '%s', '%s', %s) \n",
    "            \"\"\"\n",
    "    # Loop para importar todas as linhas do DataFrame\n",
    "    for index, row in list_result.iterrows():\n",
    "        try:\n",
    "            cursor.execute(query %(row.categoria, row.subcategoria, row.nome_produto, row.loja, row.valor ))\n",
    "            sucess += 1\n",
    "        except:\n",
    "            failure += 1\n",
    "    cnn.commit()\n",
    "    \n",
    "    dt_final = datetime.datetime.today()\n",
    "    log_insert(dt_inicio,dt_final, sucess, failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ajudar a Tratar o Preço retirando o R$ e trocando a vírgula por ponto.\n",
    "\n",
    "def limparPreco(preco):\n",
    "    preco = preco.replace('R$ ', '').replace('.', '').replace(',', '.')\n",
    "    return preco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler o arquivo CSV que contém a lista de links que serão raspados.\n",
    "\n",
    "def listaLinks(file):\n",
    "    list_links = pd.read_csv(file)\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função responsável por navegar todos os links e realizar a raspagem.\n",
    "\n",
    "def coletarPrecos(list_links, cursor):\n",
    "    list_produtos = []\n",
    "    list_erros = [] \n",
    "    \n",
    "    #contador\n",
    "    erros = 0\n",
    "    corretos = 0\n",
    "    total = len(list_links)\n",
    "    \n",
    "    for index, row in list_links.iterrows():\n",
    "        \n",
    "        print('Erros: %s/%s' %(erros, total))\n",
    "        print('Raspados: %s/%s' %((erros + corretos), total))\n",
    "        print('Link sendo consultado: %s' %(row.link))\n",
    "        \n",
    "        try:\n",
    "            corretos += 1\n",
    "            \n",
    "            #Abrir e realizar o BS4\n",
    "            data = urlopen(row.link).read()\n",
    "            soup = bs4.BeautifulSoup(data, features=\"html.parser\")\n",
    "\n",
    "            #Bs4 para localizar as Tags\n",
    "            bs4_nomes = soup.findAll('h1', {'class' : 'OverviewArea_TitleText__1s_GP'})\n",
    "            bs4_marcas = soup.findAll('img', {'class' : 'MerchantBrand_BrandImage__QoYbM'})\n",
    "            bs4_precos = soup.findAll('a', {'class' : 'PriceBox_Value__2VuFN'})\n",
    "\n",
    "            #Variavel que define o nome do Produto\n",
    "            nome_produto = bs4_nomes[0].text              \n",
    "            print(\"Produto sendo consultado: %s\" %(nome_produto))\n",
    "            \n",
    "            log_scraping(row.link, 'Success', len(bs4_precos), cursor)\n",
    "            \n",
    "            for item in range(len(bs4_precos)):\n",
    "            \n",
    "                if item == 0:\n",
    "                    print('Loja: %s | Preço: %s' %('_menor_preco_produto', bs4_precos[item].text))\n",
    "                    list_produtos.append([row.categoria, row.subcategoria, nome_produto,'_menor_preco_produto', bs4_precos[item].text, row.link, datetime.datetime.today()])\n",
    "                else:\n",
    "                    print('Loja: %s | Preço: %s' %(bs4_marcas[item-1].get('title'), bs4_precos[item].text))\n",
    "                    list_produtos.append([row.categoria, row.subcategoria, nome_produto,bs4_marcas[item-1].get('title'),bs4_precos[item].text, row.link, datetime.datetime.today()]) \n",
    "        except:\n",
    "            erros += 1\n",
    "            list_erros.append([row.link,row.categoria,row.subcategoria])    \n",
    "            log_scraping(row.link, 'Failure', 0, cursor)\n",
    "\n",
    "    return list_produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para transformar a lista de resultados em um Dataframe\n",
    "\n",
    "def transformarResultado(list_result):\n",
    "    df = pd.DataFrame(list_result, columns=['categoria','subcategoria','nome_produto', 'loja', 'valor', 'link', 'dt_insert'])\n",
    "    df['valor'] = df['valor'].apply(limparPreco)\n",
    "    df['valor'] = pd.to_numeric(df['valor'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Processo de Scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão com banco de dados radarBlackFriday\n",
    "cnn = sqlite3.connect(\"radarBlackFriday.db\")\n",
    "cursor = cnn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Registrar Log Inicio do Processo\n",
    "log_exec('Start APP')\n",
    "\n",
    "#Carregar arquivo CSV com lista dos Links\n",
    "lista = listaLinks('list_links_20.csv')\n",
    "log_exec('Lista de Links Carregada com %s links' %(len(lista)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_exec('Inicio Scraping') #Registrar LOG Inicio do Scraping\n",
    "\n",
    "result = coletarPrecos(lista , cursor) #Scraping\n",
    "result = transformarResultado(result) #Transformar Resultado em DF\n",
    "\n",
    "log_exec('Final Scraping') #Registrar LOG Final do Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_exec('Inicio Armazenamento') #Registrar LOG Inicio da importação do resultado\n",
    "\n",
    "inserirRegistros(result) # Importação do Resultado no SQLite\n",
    "\n",
    "log_exec('Final Armazenamento') #Registrar LOG Final da importação do resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finaliza processo e fecha a conexão\n",
    "log_exec('Stop APP')\n",
    "cnn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
